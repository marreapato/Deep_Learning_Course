{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marreapato/Deep_Learning_Course/blob/main/CNN_CIFAR_10_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discente: Lucas Rabelo"
      ],
      "metadata": {
        "id": "ZubmV0-vmqga"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQjHFyQvYlQf"
      },
      "source": [
        "# CIFAR-10 Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdAKVs5UYlQg"
      },
      "source": [
        "O conjunto de dados CIFAR-10 consiste em um total de 60.000 imagens coloridas de baixa resolução, distribuídas em 10 classes distintas. Cada imagem tem dimensões de 32x32 pixels, totalizando 1.024 pixels por imagem. Essas 60.000 imagens são divididas em dois conjuntos: 50.000 para treinamento e 10.000 para teste. Cada uma das 10 classes contém 5.000 imagens de treinamento e 1.000 imagens de teste. As classes do CIFAR-10 representam categorias amplas, incluindo objetos do mundo real como carros, aviões, gatos, cachorros, entre outros. Este conjunto de dados é frequentemente usado como um benchmark para avaliar algoritmos de aprendizado de máquina e redes neurais convolucionais em tarefas de classificação de imagens. É um dos conjuntos de dados mais populares na área de visão computacional e aprendizado profundo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "O significado de cada Label também está na figura abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMPXy-eYlQk"
      },
      "source": [
        "<img src=\"https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png\" style=\"width: 600px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A primeira etapa é similar ao notebook da FeedForward NN, onde os dados são separados em 80% treinamento e 20% teste"
      ],
      "metadata": {
        "id": "h5vcunhU8CGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhCtyJV6YlQq",
        "outputId": "3c12d09f-49c9-406a-f864-6316c4520b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.cifar10.load_data()\n",
        "X = np.concatenate([x_train, x_valid],axis=0)\n",
        "y = np.concatenate([y_train, y_valid],axis=0)\n",
        "\n",
        "# Divisão 80 - 20\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,shuffle=True, random_state=11) # random_state permite controlar a aleatoriedade e tornar o código mais previsível e reprodutível."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Estado aleatório é o mesmo, para garantir que o modelo feedforward nn e a cnn estão recebendo a mesma entrada."
      ],
      "metadata": {
        "id": "rPQ_V2OK8NCU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Zp-TuHhmCjjs",
        "outputId": "d0423948-fd8c-4a79-c799-119a2fd618ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78e6924a1660>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvmklEQVR4nO3de2yc5Zn//8/MeGZ8HsdxfCIHcoCEU9JtCqkXSlOS5rASgpLuF9pKG7oIBGvQQrbbNqsWCruSWZBa2ioNf+wu2UoNFFYNCNTCQmiMaJPsJiWbQsFNUkOcxHaO9thje2Y88/z+aOP+DAm5r8TObTvvlzRSYl++fD+HmcvjeebjUBAEgQAAOM/CvhcAALgwMYAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4U+F7Ah+XzeR06dEhlZWUKhUK+lwMAMAqCQD09Paqvr1c4fPrnOWNuAB06dEjTpk3zvQwAwDlqa2vT1KlTT/v5URtA69at0+OPP66Ojg4tWLBAP/zhD3XNNdec8evKysokSQ88+6LixSVO3ysajTqvKyxb8lDY8CTMUitJEcMXWNctQ8KSNY0pbHxmGgpHnGtjsZipd3E87lwbj9hO92jI/TfUIePhGQxypvp0btBQa+udHcw71wbupZKkvOHcyhmbW3a59Ry3rsWyndbwM8tK8tbeluOTd19JOpXSd7/4V0OP56czKgPopz/9qdasWaMnn3xSixYt0hNPPKHly5erpaVF1dXVH/u1J3/tFi8uUWFJqdP3YwCdwhgaQOHI6A2gonihc21hwRgaQHnbkIgYBlDYUCtJBRfAALKs42zWkjc88l8IA+ikM72MMioXIXz3u9/VnXfeqa9+9au6/PLL9eSTT6q4uFj/8R//MRrfDgAwDo34AMpkMtq5c6eWLl36528SDmvp0qXaunXrR+rT6bSSyeSwGwBg4hvxAXT06FHlcjnV1NQM+3hNTY06Ojo+Ut/U1KREIjF04wIEALgweH8f0Nq1a9Xd3T10a2tr870kAMB5MOIXIVRVVSkSiaizs3PYxzs7O1VbW/uR+ng8rrjhSiYAwMQw4s+AYrGYFi5cqM2bNw99LJ/Pa/PmzWpoaBjpbwcAGKdG5TLsNWvWaPXq1frUpz6la665Rk888YRSqZS++tWvjsa3AwCMQ6MygG699VYdOXJEDz74oDo6OvSJT3xCL7/88kcuTAAAXLhCgfVdiKMsmUwqkUho1ZM/UbSo2OlrCgxvMIwY3yw6mm9ENfU2vR1Nsizl47KaTtnb+EbUiOGNqCWO6RcnlZW6vVlZkoqjttcaCw37pTRm+1kuVuC+TySpd6DfufZ4ssfUu6tvwLk2Y3yn46AhlcH6RsfAcBrmjW/kzhvXkjckW1gfcC273P4mV/edaFlHpq9PG2//a3V3d6u8vPy0dd6vggMAXJgYQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC9GJQtuJBw70a2C/oxTbUHUPdYkYo2RMeTlWHuHQ+7ZFuGQLRokYoiRsUTlSPboHkv/bGDbzqwhHqSnwO18OqnMsFvCxTFT7+6+XlO9Iu53VWMilAYHs861fQO2fZjOuNdnDbE9ki2Kx7pT8sbIobzlvDU+TlhWYly2QmH3kzxveL6STbsdd54BAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwYs1lwmVSv8o7ZUPkC980wRLtJMmbBRWzzvMDQOxy25WTlDb1zxmy3kDFYK2zYL4P9KVPv/mSPc21BNG7qHRjy3YoyUVPvowf3m+pLyxPOtSWTqky9I9kB59pMr/v+lqS+/n7n2sCYkaaQ+3ll7R2YEtikkGUtge3+FhiWYktStGXHBYb7fba/z6mOZ0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/GbBRPOpPRoGO8RUHePaYmYozkCBkiOcLG3pEC9/qCiC1kI2qK+TFGgxgDPwpC7vuwJjHJ1LumrMi5tjBui8uZXj3FuXZqZbmpdzC12lQfjRruqgW27Tx4vMu5dv8x20NGb6bYubazyy2+Zai+O+1cm7bk2UjKhTKm+lDOvX8ob/y53xLzY+usQcNd2dI7m3aLd+IZEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLsZsFl80qEo441Q7m3QONogVuPU8KG3LMrGJyX0t40LgOQ35UKGzLdgtC7tl7khRW1rm2tjpm6n31xdOca6fW2/LX6iZXOtfGAts+VG7QVJ43ZJlF4oWm3pfUXeRcu7e11dT7+EDKufZXyb2m3u3pfufaXGB7qCswnuOBISltYND9/iBJubwhZ86Y62iIsJNhGRokCw4AMJaN+AD6zne+o1AoNOw2b968kf42AIBxblR+BXfFFVfotdde+/M3KRizv+kDAHgyKpOhoKBAtbW1o9EaADBBjMprQHv27FF9fb1mzZqlr3zlK9q/f/9pa9PptJLJ5LAbAGDiG/EBtGjRIm3YsEEvv/yy1q9fr9bWVn3mM59RT0/PKeubmpqUSCSGbtOmuV/VBAAYv0Z8AK1cuVJ//dd/rfnz52v58uX6+c9/rq6uLj377LOnrF+7dq26u7uHbm1tbSO9JADAGDTqVwdUVFTo0ksv1d69p77GPx6PKx6Pj/YyAABjzKi/D6i3t1f79u1TXV3daH8rAMA4MuID6Gtf+5qam5v1/vvv69e//rW+8IUvKBKJ6Etf+tJIfysAwDg24r+CO3DggL70pS/p2LFjmjJliq677jpt27ZNU6ZMMfVJp9OKKORUG4m4R9rkc7YonoKI+4wOuy13SNaSbWE0mHOP+wgbYkQkKRKxxZTEQhnn2r7OA6be/eXusTOZiPs6JCnVf8K5Nlpoi78Z6HePkZGkUNS9/4lU2tQ7CNxP3P4DH5h6t32wz73Ylk6kfN79C/oHbT9rx8zRV+6lGeP93hLDJGMUT96wcMs6BrNujz8jPoCeeeaZkW4JAJiAyIIDAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHgx6n+O4WxlMhmFLQFLjuKx6KjVFxhzmALD3s/Ilr8WMcRH2faIVJCx5ZgVFrqvvWzQ9hdxI8cPOtem8rZ1Hz1+2Lk21Ndt693eYaoPF5U513ZlbFljk2fMcK4tKrb96ZS+tj8415ZWVpt6K+ueBZfK2c5ya3ZcJJd3rrXdk2VKahzM2Y59zpBLF4TcH49z6QGnOp4BAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8GLNRPD09PQrH0k61BQXumzGYtUVyZDMR59qCiG2eW5J7gnzG1jvrHg1SHLKte2ZFkal+YXWVc+1lgS0uZ3ZJoXtxzP1YSlLb8SPOtV0H9pl653tt0T0qLHUunWKMtKlPxJxr44WG/S0pWlLiXHu4z3bs2wvc19KVswXg9Ay6PfaclDHEHwWBLWJsMO++dkOyzp96G9ZtiEbLpd32H8+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6M2Sy4IMgpH7hlIOUNm5Ez5CpJUjbjnqnmXvlHsYh7DlM4ZOtuyZsqith6zy21nTaTjrQ51yb7U6benRH3fLdQb9LUu/fYcefaWN62TyIlFab6WKLcuXYgPWDqffTgQefaotIyU+/jBwzHfsCWdzhp2izn2orAlgGZztnuE4Nh9+OfMQa2DeYNj0GBrXfOkJFnyoLLZ53qeAYEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8GLMZsFFCwoULnBbXsSxTpLCIfc8I0kKDFlJYdlymEKGvKlwxHaoJhfFnWsvr4yZek+N9ZvqJ0XdcqEk6YprrzP1Liid5Fx7ZP8Hpt6x4iLn2oGM+zZKUjo0aKoPx9yPZzBoyzGLGc6taZfOM/WeWj/Vufbd7b8x9Y4Mut+XTxiz+pLGvLa+qHv/gkFb5l0+4r6dWeOxDwzZmDnDLsnl3M5vngEBALwwD6A33nhDN954o+rr6xUKhfT8888P+3wQBHrwwQdVV1enoqIiLV26VHv27Bmp9QIAJgjzAEqlUlqwYIHWrVt3ys8/9thj+sEPfqAnn3xS27dvV0lJiZYvX66BAVtEPABgYjO/BrRy5UqtXLnylJ8LgkBPPPGEvvWtb+mmm26SJP34xz9WTU2Nnn/+ed12223ntloAwIQxoq8Btba2qqOjQ0uXLh36WCKR0KJFi7R169ZTfk06nVYymRx2AwBMfCM6gDo6OiRJNTU1wz5eU1Mz9LkPa2pqUiKRGLpNmzZtJJcEABijvF8Ft3btWnV3dw/d2trc/4QvAGD8GtEBVFtbK0nq7Owc9vHOzs6hz31YPB5XeXn5sBsAYOIb0QE0c+ZM1dbWavPmzUMfSyaT2r59uxoaGkbyWwEAxjnzVXC9vb3au3fv0P9bW1u1a9cuVVZWavr06br//vv1L//yL7rkkks0c+ZMffvb31Z9fb1uvvnmkVw3AGCcMw+gHTt26HOf+9zQ/9esWSNJWr16tTZs2KCvf/3rSqVSuuuuu9TV1aXrrrtOL7/8sgoLC03fJ5vOKOyYKpHNusdJRCMR0zoSJcXOtZNK3eNSJCluiO9Q1hbdMqfAfZ98Qn2m3pfm06b6injUuXbgfVtcjiKdZ675kwLje9FK4u4RRSXGi2f27fm9qb4o4n6MKmO2u3XhiaPOtcd2bDP1Pt7b5Vw7KWyLvykx3Cf6s7b7/ZFi20sBB0Puj2/lxSWm3gq7r72713Zf7up2v+p4oM/9/pN3jKYyD6DFixcrCE5/ooRCIT3yyCN65JFHrK0BABcQ71fBAQAuTAwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF+YonvNmMC+FHMPggpBz20jYNnOjhnyq0iL37DBJShiy40rTPabeVwz0OtdO73TPU5MkpbpN5b1FRc618cip/3Dh6YRy7scnGbjn40nSQHnCuXb2or809W5rPWBbS+dx59ryQvf7gyTl0u7ZfulBx/vkSXH3+1uo1NY7EXU/nrOLbPlrxwts2YvhWL1zbUHFJFPvckN9KmM7x/f+wT17ceDgIefafMTtuPMMCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZiN4okVFChc4LY89zAWKWKqlkoK3eN1qqdUmnpPibmvZaYx/ubS3qRz7aQe91pJ6upzj26RpI5B9+2MybaWhCEqKR21RSUFZTXOtfHaKabetXPnmOqP/XaXc23PwAlT74JQ1rk2VFxo6h2OuscChUps8Tel1e69C0O2iJr+o7boq/6BlHNtZLItiqfHcH87fvioqXc+m3GujYUjzrU5x1qeAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8GLNZcJFYSOGYW9bTrJpq577T6y4yrSMfc8+QKsq650FJ0vRu9/rLUsdNvcv73LOsonFbRlo8ZDxtBt0zvo6l86bWPY7niCSlA/fcK0mKGjK45gy6r0OSjnfbsv2yBe4/K8bLEqbeR1Pu52H/gC1LMZ4ccK4dOOGeSSdJ3W3u9UHYfR2SlBvsN9WXyP1xIjdlqql3ea37Y1Yoa8uZu2LGdOfaw73u52ymv18tT525jmdAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvxmwUT3/XcYWiUafaWO1k575TymyxM2WVRe69e20xMlU73nEv7mwz9e4PucffDBTFTb2DYts+LI8WOtdeNG2eqXck7r721r2tpt6dJ9wjao4dt0XrHE/a6k90tDvX1hUVm3oP9rnH1OQH+ky984H7fSIdiph6Dwbu8Uf5wD0qR5JSadvxmRRxj3k6sec9U++q2Rc7115cO9vUezDjvu5czD2GKd3nNlp4BgQA8IIBBADwwjyA3njjDd14442qr69XKBTS888/P+zzt99+u0Kh0LDbihUrRmq9AIAJwjyAUqmUFixYoHXr1p22ZsWKFWpvbx+6Pf300+e0SADAxGO+CGHlypVauXLlx9bE43HV1tae9aIAABPfqLwGtGXLFlVXV2vu3Lm65557dOzYsdPWptNpJZPJYTcAwMQ34gNoxYoV+vGPf6zNmzfrX//1X9Xc3KyVK1cqlzv1ZZBNTU1KJBJDt2nTpo30kgAAY9CIvw/otttuG/r3VVddpfnz52v27NnasmWLlixZ8pH6tWvXas2aNUP/TyaTDCEAuACM+mXYs2bNUlVVlfbu3XvKz8fjcZWXlw+7AQAmvlEfQAcOHNCxY8dUV1c32t8KADCOmH8F19vbO+zZTGtrq3bt2qXKykpVVlbq4Ycf1qpVq1RbW6t9+/bp61//uubMmaPly5eP6MIBAOObeQDt2LFDn/vc54b+f/L1m9WrV2v9+vXavXu3/vM//1NdXV2qr6/XsmXL9M///M+KGzK7JGlScakiUbfMsckVCee+XcePmNYRC9zXXR+15U2V9/U61xYMuucwSVKkyJDX5ha5NyRmixpTJtPvXJs9ccjUO5tzP4UH2o+aeg/Gypxru453mXr39Noy1TJ97pldAwO2TMKSQffzNhG2/dJkMO/euydly18rLHQ/EaNh2+NPeMB2fyuWe55ezpinlzA8SvcH7ueJJH3QftC5dv9h9/tPZsBtf5gH0OLFixUEpz84r7zyirUlAOACRBYcAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLEf97QCOlvKRIkZhbnlkkbNgMY5bV798/4N463WXqfUOp+5+eCBcVmnoHQdq5tqzAlh0Wky0nKxqEnGtTR91z4ySpN+2eNdbdZftru10R9/1SGi8x9e4+fNxUnzzqXh8vsa0lXljkXBspsAUHxsLu9YUxW15byPDzcyhkW3dhYampvieIONe+n7Rl3mV6epxr6ybXm3rPmTbduXbG9Iuda/tTKT3rUMczIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF2M2iueiaTWKFrrFz2Qzg859k/3u0S2SdCTlHjvTcbDT1Lu8MmFYiHskkCRNCrlv57zJFabe0bz7/pakPkNU0rvH3WNHJKm9P+VcG6m0xauU11zsXltXa+pdaNzn+ZB7xEo26h4LI0nvGs7buowt0mZS2H0t5RHbw1Es5t47a4hVkqRskW0ftkfc44/eG7RFWe17b59z7aXdtu38xIwZzrV/efUC59repFvsFc+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6M2Sy4VZ9fquJSt+yuDw4ede775s7dpnUcP9HrXHto/wlT7+xh996fqrblmFVUxJ1rM3HbzyEnDh801R9N9TvXfnDIuA8nVTjXVl421dT7L2/8f861F89faOqd/fkzpnqFM86lQcZ2tz52oN25dlLFJFPvXHGlc224rMzUO19S5FzbFqRNvQ9EbZl3LQPu+Yi5SltuYHen++PbpLD7PpGkyMzZzrVRQ4ZdgWMtz4AAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6M2SieqtIylThG8ZRdUuHcN53Pm9Zx4MAHzrWDqayp93tH3KN42g91mnrvLgw51y6oLDH1vjhhO22KIu71s6YkTL1jJcXOtT1Hjpl6T+p3j7+JHjli6n1R2j2eSJIGet3PlUjK/dhLUmlZtXNtPG47V47E3I/P73O2++bBQ+4RQgcMx1KSemK287Bi+gzn2tJCW1zOpIR7DNfixZ8x9a6aVOVc29bR4VybcjxfeQYEAPDCNICampp09dVXq6ysTNXV1br55pvV0tIyrGZgYECNjY2aPHmySktLtWrVKnV22n56BwBMfKYB1NzcrMbGRm3btk2vvvqqstmsli1bplQqNVTzwAMP6MUXX9Rzzz2n5uZmHTp0SLfccsuILxwAML6Zfpn/8ssvD/v/hg0bVF1drZ07d+r6669Xd3e3/v3f/10bN27UDTfcIEl66qmndNlll2nbtm369Kc/PXIrBwCMa+f0GlB3d7ckqbLyj3/zY+fOncpms1q6dOlQzbx58zR9+nRt3br1lD3S6bSSyeSwGwBg4jvrAZTP53X//ffr2muv1ZVXXilJ6ujoUCwWU0VFxbDampoadZzmCoqmpiYlEomh27Rp0852SQCAceSsB1BjY6PefvttPfOM8S87fsjatWvV3d09dGtrazunfgCA8eGs3gd077336qWXXtIbb7yhqVP//GeOa2trlclk1NXVNexZUGdnp2prT/1naOPxuOJx9z8fDQCYGEzPgIIg0L333qtNmzbp9ddf18yZM4d9fuHChYpGo9q8efPQx1paWrR//341NDSMzIoBABOC6RlQY2OjNm7cqBdeeEFlZWVDr+skEgkVFRUpkUjojjvu0Jo1a1RZWany8nLdd999amho4Ao4AMAwpgG0fv16SdLixYuHffypp57S7bffLkn63ve+p3A4rFWrVimdTmv58uX60Y9+NCKLBQBMHKYBFATBGWsKCwu1bt06rVu37qwXJUld3SeUGXTLVquum3rmoj+5Ys4s0zrem3Wxc+3+XW+bevce63auPZS2XZ7e3tfnXPt2PmfqfVGle76XJF02bbJz7cXlttcDawbda0vzMVPvd9/8lXPtB/+329Q7SJvKVVpxkXPt8UHbuXI47r4TT+Sipt7vtRny2nqPmnqXGzIMs4O2fLzElApT/azp7lfv/vqdt0y9L557iXNtdZX7fU2SlD/zY/pJ7+xpOXPRn/Q7Pv6QBQcA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8OKs/hzD+VBcWKTioiKn2kNt7zv3jZSWmtZx3WfcU7w7D5z6j+6dzv+8+rpzbT59zNQ7GnP/2SKbscWUvNtpi3p590iXc21pxD0aRJJKC9xP4Vhhoal3rHSnc21xmXssjCSle1Km+lzWPS5pwNRZ6gu7RxT1G6KPJCmX7HKunVdju28umFLpXDsQcYv1Oql8ji3Spi973Lm2uqba1PvTn/qUc2140HaADu0/4FxbO6XKubYv5XZ+8wwIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWYzYJL9/UrEnKbj50dh5z7dvTacszm/sVC59rLrv6Eqff7rR841x7YbVt3rrvbuTaSz5h6R8O2vKlBw485vcassd6sITsubWyect+HBcdt2W6BMX8vl3fPa1Nx3NRbUfe1hLJpW+9B9wy77lSfqXU6FHWurZox09Q7U2bLa6uqneFcu/Rm92w3Saqrq3Ou7ek4aupdXZZwrq2c7J691xtzOwd5BgQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8GLMRvGs/do/KRxxW155Walz33zEFoFy7NAx59p5n/wLU+/rll3vXLujpMjU+w87fuNcm253jzKSpIIga6qP5twjcAZDhmgdSQobYmTyttahQUPvnHvkjCRFDDEykhQOGfobo5XCefd9nsvZ4nKihtO26uKLTL2nfupq59qLF3zS1LunoNBUL8fYMElKnugytT5x9IRz7b6WvabeRw3RPW1tB51rB7NujxE8AwIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MWaz4No+6FDIMV8pIku+my1r7NiRbufavr60qXfV1Drn2s8vW2zqnVxwpXPt9tc2m3of/P3vTfUDSfd9GMna9mGQd8+ZC2Trnc9bzivbz3KD6jfVJ8rd8w4nV5WYemcNWX3l5dNMvS+77BLn2k//5TWm3ldfd51z7aETvabebzX/2lTf+of3nWv3v/+BqbfCEefSZMqW1Zc0PGblAvf7Q+CYjcgzIACAF6YB1NTUpKuvvlplZWWqrq7WzTffrJaWlmE1ixcvVigUGna7++67R3TRAIDxzzSAmpub1djYqG3btunVV19VNpvVsmXLlEqlhtXdeeedam9vH7o99thjI7poAMD4Z3oN6OWXXx72/w0bNqi6ulo7d+7U9df/+W/bFBcXq7a2dmRWCACYkM7pNaDu7j++uFxZWTns4z/5yU9UVVWlK6+8UmvXrlVf3+lfGEun00omk8NuAICJ76yvgsvn87r//vt17bXX6sor/3zF1Ze//GXNmDFD9fX12r17t77xjW+opaVFP/vZz07Zp6mpSQ8//PDZLgMAME6d9QBqbGzU22+/rTfffHPYx++6666hf1911VWqq6vTkiVLtG/fPs2ePfsjfdauXas1a9YM/T+ZTGraNNulngCA8eesBtC9996rl156SW+88YamTp36sbWLFi2SJO3du/eUAygejysej5/NMgAA45hpAAVBoPvuu0+bNm3Sli1bNHPmzDN+za5duyRJdXXub7oEAEx8pgHU2NiojRs36oUXXlBZWZk6OjokSYlEQkVFRdq3b582btyov/qrv9LkyZO1e/duPfDAA7r++us1f/78UdkAAMD4ZBpA69evl/THN5v+/z311FO6/fbbFYvF9Nprr+mJJ55QKpXStGnTtGrVKn3rW98asQUDACaGUBAEtnC0UZZMJpVIJBSrvEQhxwykUMiQURS4ZRQN1Re4966omWLqPXWm+8UW8xdcYeo965Iz/3r0pD+8/76p92//b7ep/uCePzjXptqPmnoPJLuca7OZHlNv5d3PlUjE9nJqPGp7B0RJUcy5durUalPvyy9zP7eu+ourTb1nGLLg4pMSpt796bxz7bNPbzL1fv3nW0z1Pcfd8w5leLySpFiJew5gQVGRqXeoIOpcm3fM5pSkIJ/TwP7/U3d3t8rLy09bRxYcAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLMRvFU1A8QyHX6AdLtEXYurnu9bFC97gUSZoxxz0u56JLPv7PXnxY9fR659rJ9bak8sLiYlN9f5d7BM5gT7+p97EDbc61XUcPmnpnBgaca8OOsVEnTa60xc7EDEk/RUW2WKA5c+e5r6Nskql3Kj/oXPv7D/abep840etcmyisMPWO5W378L3fvONcu2P7DlPvIGx4nmCplZQzPL6FDL2DIKfgxB+I4gEAjE0MIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF7bAo/MpPSA5ZsHlDXlGCtmy4ELKO9cO9LlnnklS2+/cs8aO7P/A1DtiCA+bUlNt6n3x7Fmm+iuuutK5dtqs2abeJZ9w711cVmjqbfn5rLsnZeqcHXTPSJOkREWpc+2x44dNvTOZjHNtrLDE1DuddM9ru6jCPb9QkooGTzjXRoxZff29fab6rv6kc23O+Kgb5NzPlVBgyMWUFHbN25QUCdwfC4Mgr6zL93fuCADACGIAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvAgFQWDLphllyWRSiURCIVUoJMdYCVv6hEnI0Nu6KwNLtIUhEujkV7jLGXvb1hIOx5xrSxPlpt6JqknOtbMuu8TU+9rPXu9cO6W2ztTbdGJJSnZ3O9fu3fN7U++SoiLnWmOSlToOtjvXRsO2jJpfv/lr59oD79uirGS4b0qSCtz3oWSLBQoZHldChmgdyfjQaVhHEOSVzxxWd3e3ystPf5/mGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAizGbBSeVKmTMyxp/DLs+NHpZcNa9HJhy5kwRUvYMLouILWusuLzMuTZaGDf1LojY8sAG+vqca9N9A6bekYjl51Db2ZJOpw3Vxp+Hc5b7j/EsN2aqKXA/nqHAthbL3cf6mDlaj7FBkFeQP0YWHABgbDINoPXr12v+/PkqLy9XeXm5Ghoa9Itf/GLo8wMDA2psbNTkyZNVWlqqVatWqbOzc8QXDQAY/0wDaOrUqXr00Ue1c+dO7dixQzfccINuuukmvfPOO5KkBx54QC+++KKee+45NTc369ChQ7rllltGZeEAgPHtnF8Dqqys1OOPP64vfvGLmjJlijZu3KgvfvGLkqT33ntPl112mbZu3apPf/rTTv14Deg0eA3o3PEa0CnxGtCp6nkN6FyM+mtAuVxOzzzzjFKplBoaGrRz505ls1ktXbp0qGbevHmaPn26tm7deto+6XRayWRy2A0AMPGZB9Bvf/tblZaWKh6P6+6779amTZt0+eWXq6OjQ7FYTBUVFcPqa2pq1NHRcdp+TU1NSiQSQ7dp06aZNwIAMP6YB9DcuXO1a9cubd++Xffcc49Wr16t3/3ud2e9gLVr16q7u3vo1tbWdta9AADjh+2X4pJisZjmzJkjSVq4cKH+93//V9///vd16623KpPJqKura9izoM7OTtXW1p62XzweVzxu+/05AGD8O+f3AeXzeaXTaS1cuFDRaFSbN28e+lxLS4v279+vhoaGc/02AIAJxvQMaO3atVq5cqWmT5+unp4ebdy4UVu2bNErr7yiRCKhO+64Q2vWrFFlZaXKy8t13333qaGhwfkKOADAhcM0gA4fPqy/+Zu/UXt7uxKJhObPn69XXnlFn//85yVJ3/ve9xQOh7Vq1Sql02ktX75cP/rRj85yaVkFzpcrjtPLtUOGS6WtV8sbetuvw7de6jl6l8uGw4bLmQPbE/50b797bX/G1DufGzTVB3n3fRg2Hp8gk3OvNXWWIiHL5ebGdZvKjb2t7wYwnLeB5Zz941dYFjJqnS3vp3AtHcNZcHG578wLYABZ7/qWB30z+zuHRqv3aA4ghQ31xvf1jKUBZPnhxnpWhUzvpzE+eJoWM5q9JRkGbWAaypLtPX2j+FhoGkB5KSALDgAwRjGAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6Y07BH25+DGcZUQMPoML0D3bo/xtL+G721mII8rG9vH8Xe5gCSUUwrGNXeo3rsR631WfS2ZPeMXpJIMEaSEE5mGZ3pPB9zA6inp+dP/7Jla+FDxtL8GUV59xizs2huqLUl64yqsfSjytgK+hpFpj87P2qrGHN6enr+FK12amMuCy6fz+vQoUMqKysb9vfKk8mkpk2bpra2to/NFhrv2M6J40LYRontnGhGYjuDIFBPT4/q6+sV/phMxTH3DCgcDmvq1Kmn/Xx5efmEPvgnsZ0Tx4WwjRLbOdGc63Z+3DOfk7gIAQDgBQMIAODFuBlA8XhcDz30kOLxuO+ljCq2c+K4ELZRYjsnmvO5nWPuIgQAwIVh3DwDAgBMLAwgAIAXDCAAgBcMIACAF+NmAK1bt04XX3yxCgsLtWjRIv3P//yP7yWNqO985zsKhULDbvPmzfO9rHPyxhtv6MYbb1R9fb1CoZCef/75YZ8PgkAPPvig6urqVFRUpKVLl2rPnj1+FnsOzrSdt99++0eO7YoVK/ws9iw1NTXp6quvVllZmaqrq3XzzTerpaVlWM3AwIAaGxs1efJklZaWatWqVers7PS04rPjsp2LFy/+yPG8++67Pa347Kxfv17z588ferNpQ0ODfvGLXwx9/nwdy3ExgH76059qzZo1euihh/Sb3/xGCxYs0PLly3X48GHfSxtRV1xxhdrb24dub775pu8lnZNUKqUFCxZo3bp1p/z8Y489ph/84Ad68skntX37dpWUlGj58uUaGBg4zys9N2faTklasWLFsGP79NNPn8cVnrvm5mY1NjZq27ZtevXVV5XNZrVs2TKlUqmhmgceeEAvvviinnvuOTU3N+vQoUO65ZZbPK7azmU7JenOO+8cdjwfe+wxTys+O1OnTtWjjz6qnTt3aseOHbrhhht000036Z133pF0Ho9lMA5cc801QWNj49D/c7lcUF9fHzQ1NXlc1ch66KGHggULFvhexqiRFGzatGno//l8PqitrQ0ef/zxoY91dXUF8Xg8ePrppz2scGR8eDuDIAhWr14d3HTTTV7WM1oOHz4cSAqam5uDIPjjsYtGo8Fzzz03VPPuu+8GkoKtW7f6WuY5+/B2BkEQfPaznw3+/u//3t+iRsmkSZOCf/u3fzuvx3LMPwPKZDLauXOnli5dOvSxcDispUuXauvWrR5XNvL27Nmj+vp6zZo1S1/5yle0f/9+30saNa2trero6Bh2XBOJhBYtWjThjqskbdmyRdXV1Zo7d67uueceHTt2zPeSzkl3d7ckqbKyUpK0c+dOZbPZYcdz3rx5mj59+rg+nh/ezpN+8pOfqKqqSldeeaXWrl2rvr4+H8sbEblcTs8884xSqZQaGhrO67Ecc2GkH3b06FHlcjnV1NQM+3hNTY3ee+89T6saeYsWLdKGDRs0d+5ctbe36+GHH9ZnPvMZvf322yorK/O9vBHX0dEhSac8ric/N1GsWLFCt9xyi2bOnKl9+/bpn/7pn7Ry5Upt3bpVkUjE9/LM8vm87r//fl177bW68sorJf3xeMZiMVVUVAyrHc/H81TbKUlf/vKXNWPGDNXX12v37t36xje+oZaWFv3sZz/zuFq73/72t2poaNDAwIBKS0u1adMmXX755dq1a9d5O5ZjfgBdKFauXDn07/nz52vRokWaMWOGnn32Wd1xxx0eV4Zzddtttw39+6qrrtL8+fM1e/ZsbdmyRUuWLPG4srPT2Niot99+e9y/Rnkmp9vOu+66a+jfV111lerq6rRkyRLt27dPs2fPPt/LPGtz587Vrl271N3drf/6r//S6tWr1dzcfF7XMOZ/BVdVVaVIJPKRKzA6OztVW1vraVWjr6KiQpdeeqn27t3reymj4uSxu9COqyTNmjVLVVVV4/LY3nvvvXrppZf0y1/+ctifTamtrVUmk1FXV9ew+vF6PE+3naeyaNEiSRp3xzMWi2nOnDlauHChmpqatGDBAn3/+98/r8dyzA+gWCymhQsXavPmzUMfy+fz2rx5sxoaGjyubHT19vZq3759qqur872UUTFz5kzV1tYOO67JZFLbt2+f0MdVkg4cOKBjx46Nq2MbBIHuvfdebdq0Sa+//rpmzpw57PMLFy5UNBoddjxbWlq0f//+cXU8z7Sdp7Jr1y5JGlfH81Ty+bzS6fT5PZYjeknDKHnmmWeCeDwebNiwIfjd734X3HXXXUFFRUXQ0dHhe2kj5h/+4R+CLVu2BK2trcGvfvWrYOnSpUFVVVVw+PBh30s7az09PcFbb70VvPXWW4Gk4Lvf/W7w1ltvBR988EEQBEHw6KOPBhUVFcELL7wQ7N69O7jpppuCmTNnBv39/Z5XbvNx29nT0xN87WtfC7Zu3Rq0trYGr732WvDJT34yuOSSS4KBgQHfS3d2zz33BIlEItiyZUvQ3t4+dOvr6xuqufvuu4Pp06cHr7/+erBjx46goaEhaGho8LhquzNt5969e4NHHnkk2LFjR9Da2hq88MILwaxZs4Lrr7/e88ptvvnNbwbNzc1Ba2trsHv37uCb3/xmEAqFgv/+7/8OguD8HctxMYCCIAh++MMfBtOnTw9isVhwzTXXBNu2bfO9pBF16623BnV1dUEsFgsuuuii4NZbbw327t3re1nn5Je//GUg6SO31atXB0Hwx0uxv/3tbwc1NTVBPB4PlixZErS0tPhd9Fn4uO3s6+sLli1bFkyZMiWIRqPBjBkzgjvvvHPc/fB0qu2TFDz11FNDNf39/cHf/d3fBZMmTQqKi4uDL3zhC0F7e7u/RZ+FM23n/v37g+uvvz6orKwM4vF4MGfOnOAf//Efg+7ubr8LN/rbv/3bYMaMGUEsFgumTJkSLFmyZGj4BMH5O5b8OQYAgBdj/jUgAMDExAACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAePH/AVO6aBYer5O4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = x_train[0]\n",
        "plt.imshow(image)#boat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVZRnoLlDHsh",
        "outputId": "90808ab0-2359-4aa6-a172-30e0eb948ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[0])# Barco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeyBCqhEYlQq"
      },
      "source": [
        "### Pré-Processamento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYbHQtgGYlQr"
      },
      "source": [
        "A Normalização é aplicada, no entanto não existe a necessidade de realizar o flattening no pré-processamento, já que a rede cnn aceita a entrada em tensores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkZXx0mLYlQr"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDRrEf7BH6fh"
      },
      "source": [
        "Categorical Enconding (Ortogonalização) é aplicada nas labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NBobdFqH5kG",
        "outputId": "911c7ec9-eef0-4108-89df-a5262b5bf37c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8],\n",
              "       [6],\n",
              "       [6],\n",
              "       ...,\n",
              "       [9],\n",
              "       [3],\n",
              "       [3]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwrIjswvIszq"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10 # categorias de 0 a 9\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgPLVqvwKBgL",
        "outputId": "08f0566e-08af-4a41-fb0d-a44efa4a5d5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z41JAZjMqJwJ"
      },
      "source": [
        "### Construindo o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZG6iHQOqJwJ"
      },
      "source": [
        "Primeiramente é adicionada uma camada convolucional (Conv2d) ao modelo, com filtros de janelas 3x3 e volume de 32, o stride selecionado é de 1 (ou seja o filtro é aplicado pulando apenas uma  coluna de pixel), o parametro padding é \"same\" ou seja a reolução da imagem será mantida durante a aplicação da camada convolucional.\n",
        "\n",
        "A camada de MaxPooling2d 2x2 com stride 2 diminui a resolução da imagem pela metade (no final teremos a matriz de 8x8, lembrando que iniciamos com 32x32), tornando o modelo mais robusto e dinâmico\n",
        "\n",
        "Antes da camada Fully Connected é aplicada uma cada de Flatten para que as operações sejam realizadas pela camada fully connected (seguindo a mesma lógica do flattening na feedforward do script anterior)\n",
        "\n",
        "As camadas de normalização (BatchNormalization) aplicam a normalização dentro do modelo e a camada de Dropout desliga algumas conexões da camada anterior, na arquitetura escolhida foram aplicadas duas camadas de dropout desligando aleatoriamente 25% das conexões das camadas antecessoras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUXpoAXPqJwK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPool2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding=\"same\", input_shape=(32,32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding=\"same\"))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding=\"same\"))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(420, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rRXIj6TqJwN"
      },
      "source": [
        "### Sumário do Modelo (Será comentado no final junto com a performance e comparação com o modelo do primeiro script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvEs89JOqJwO",
        "outputId": "8b58b6fe-b3d5-4fe2-c86d-6d24dc5c0185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 420)               860580    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 420)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                4210      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 884310 (3.37 MB)\n",
            "Trainable params: 884246 (3.37 MB)\n",
            "Non-trainable params: 64 (256.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOBZkDoFqJwP"
      },
      "source": [
        "### Ajuste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QdhjvDXqJwP"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDTuiKREqJwQ",
        "outputId": "25611637-382d-499b-fc32-cf5faa0c733e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 20s 6ms/step - loss: 1.4056 - accuracy: 0.5001 - val_loss: 1.4321 - val_accuracy: 0.5116\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 1.0496 - accuracy: 0.6333 - val_loss: 1.0007 - val_accuracy: 0.6513\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.9235 - accuracy: 0.6818 - val_loss: 1.0173 - val_accuracy: 0.6436\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.8524 - accuracy: 0.7099 - val_loss: 0.9472 - val_accuracy: 0.6743\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7997 - accuracy: 0.7309 - val_loss: 0.9057 - val_accuracy: 0.6917\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7712 - accuracy: 0.7413 - val_loss: 0.9644 - val_accuracy: 0.6938\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7411 - accuracy: 0.7499 - val_loss: 1.0019 - val_accuracy: 0.6837\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.7095 - accuracy: 0.7637 - val_loss: 0.9308 - val_accuracy: 0.6951\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6925 - accuracy: 0.7679 - val_loss: 0.8568 - val_accuracy: 0.7163\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6572 - accuracy: 0.7802 - val_loss: 0.8776 - val_accuracy: 0.7114\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A Acurácia no conjunto de treinamento começa em torno de 50.01% e aumenta para cerca de 78.02% após 10 épocas. Isso indica que o modelo está aprendendo bem os padrões nos dados de treinamento, visto que a loss também diminui ao longo das épocas, indicando que o modelo está otimizando seus pesos para se ajustar melhor aos dados de treinamento.\n",
        "\n",
        "Já no conjunto de validação a acurácia começa em torno de 51.16% e aumenta para cerca de 71.14% após 10 épocas. Mostrando que o modelo está generalizando bem e evitando overfitting. A loss no conjunto de validação também diminui de forma constante, o que é positivo, pois mostra que o modelo está melhorando sua capacidade de generalização.\n"
      ],
      "metadata": {
        "id": "HkAZaBUNFyi0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlluCyqHYlQ1"
      },
      "source": [
        "## Discussão do Sumário do modelo (Comparação com FeedForward NN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQudS7iYlQ1"
      },
      "source": [
        "Este modelo tem consideravelmente menos parâmetros (cerca de 884.310) em comparação com o modelo anterior (aproximadamente 1.471.690). A redução na quantidade de parâmetros pode tornar o modelo menos propenso ao overfitting, a adição de camadas de Batch Normalization e Dropout também contribui para a regularização e pode ajudar a controlar o overfitting (possivelmente verificado no modelo anterior).\n",
        "\n",
        "No geral, esse modelo parece ser mais eficiente em termos de parâmetros (houve uma diminuição de 39% no número de parâmetros em comparação a Rede Neural Simples e possui componentes de regularização que podem melhorar o desempenho em relação ao modelo anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zphtHUE2C3Is"
      },
      "source": [
        "## Discussão da performance do modelo (Comparação com FeedForward NN)\n",
        "\n",
        "\n",
        "Este modelo CNN parece ser mais eficaz, com uma acurácia de validação mais alta em comparação com o modelo feedforward anterior, que estava sofrendo de overfitting. A introdução de camadas convolucionais, max-pooling e dropout, com uma arquitetura de CNN, parece ter sido mais apropriada para previsão, visto que o número de neurônios da camada fully connected do modelo foi o mesmo (420 neurônios) para os dois modelos\n",
        "\n",
        "Apesar do desempenho do modelo CNN poder ser ainda mais otimizado, a acurácia no conjunto de validação sugere que o modelo está generalizando bem para dados não vistos.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}