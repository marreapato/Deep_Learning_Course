{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5Ykl6T5n48to1VMM9gdXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marreapato/Deep_Learning_Course/blob/main/Reading_MIT_Indoor_Scene.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oigHXLHyJe9W",
        "outputId": "3901232f-3fc6-4130-f25c-e6aa4533baa5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Fundamentals_Deep_Learning\n",
        "\n",
        "!ls\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhDZwWHlJhn4",
        "outputId": "1602d54a-8881-4f79-d674-ace880c999a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Fundamentals_Deep_Learning\n",
            " 001_tensorflow.ipynb\t\t     06_headline_generator.ipynb\n",
            " 00_jupyterlab.ipynb\t\t     activities.csv\n",
            " 01_mnist.ipynb\t\t\t     asl_model\n",
            " 02_asl.ipynb\t\t\t     BANKEX.csv\n",
            " 03_asl_cnn.ipynb\t\t    'CoÃÅpia de 01_mnist.ipynb'\n",
            " 04a_asl_augmentation.ipynb\t     data\n",
            " 04b_asl_predictions.ipynb\t     images\n",
            " 05a_doggy_door.ipynb\t\t    'NN FeedForward - CIFAR - 10.ipynb'\n",
            " 05b_presidential_doggy_door.ipynb   RNN_multi.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pdGZdoJn2GB",
        "outputId": "89b09f13-0942-4915-f997-9a5bbcdf61c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded the dataset to /content/gdrive/MyDrive/Fundamentals_Deep_Learning/mit_indoor_scene_dataset/indoorCVPR_09.tar.gz\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Define the URL of the dataset\n",
        "url = \"http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar\"\n",
        "\n",
        "# Define the directory where you want to save the dataset\n",
        "save_dir = \"/content/gdrive/MyDrive/Fundamentals_Deep_Learning/mit_indoor_scene_dataset\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Define the path where you want to save the downloaded file\n",
        "save_path = os.path.join(save_dir, \"indoorCVPR_09.tar.gz\")\n",
        "\n",
        "# Send an HTTP GET request to download the dataset\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Open the file in binary write mode and write the content of the response\n",
        "    with open(save_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"Downloaded the dataset to {save_path}\")\n",
        "else:\n",
        "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
        "\n",
        "# You can now extract the contents of the downloaded tar.gz file using Python's tarfile module if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# For separating train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "39S02-I-puUI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Define the path to an example image\n",
        "image_path = \"/content/gdrive/MyDrive/Fundamentals_Deep_Learning/mit_indoor_scene_dataset/indoorCVPR_09.tar.gz\"\n",
        "\n",
        "\n",
        "\n",
        "t = tarfile.open(image_path, 'r')\n",
        "for member in t.getmembers():\n",
        "    if \".jpg\" in member.name:\n",
        "        t.extract(member, \"outdir\")\n",
        "\n",
        "print(os.listdir('outdir'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1_Viwsapd9O",
        "outputId": "0e487fed-03ec-4cb2-c15b-3606e3d1e0e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Data\n"
      ],
      "metadata": {
        "id": "AgcRh3LmPFpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Define the data transformation pipeline\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),     # Resize the image to (224, 224)\n",
        "    transforms.ToTensor(),             # Convert image to tensor\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "# Specify the root directory of your dataset\n",
        "data_dir = '/content/gdrive/MyDrive/Fundamentals_Deep_Learning/outdir/Images'\n",
        "\n",
        "# Create an instance of the ImageFolder dataset\n",
        "train_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=data_dir, transform=data_transform)\n",
        "\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))"
      ],
      "metadata": {
        "id": "XehD2xPsPIOj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq4PDMSJTf4e",
        "outputId": "91ed46ce-3102-42a0-d948-784616fdb825"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airport_inside': 0,\n",
              " 'artstudio': 1,\n",
              " 'auditorium': 2,\n",
              " 'bakery': 3,\n",
              " 'bar': 4,\n",
              " 'bathroom': 5,\n",
              " 'bedroom': 6,\n",
              " 'bookstore': 7,\n",
              " 'bowling': 8,\n",
              " 'buffet': 9,\n",
              " 'casino': 10,\n",
              " 'children_room': 11,\n",
              " 'church_inside': 12,\n",
              " 'classroom': 13,\n",
              " 'cloister': 14,\n",
              " 'closet': 15,\n",
              " 'clothingstore': 16,\n",
              " 'computerroom': 17,\n",
              " 'concert_hall': 18,\n",
              " 'corridor': 19,\n",
              " 'deli': 20,\n",
              " 'dentaloffice': 21,\n",
              " 'dining_room': 22,\n",
              " 'elevator': 23,\n",
              " 'fastfood_restaurant': 24,\n",
              " 'florist': 25,\n",
              " 'gameroom': 26,\n",
              " 'garage': 27,\n",
              " 'greenhouse': 28,\n",
              " 'grocerystore': 29,\n",
              " 'gym': 30,\n",
              " 'hairsalon': 31,\n",
              " 'hospitalroom': 32,\n",
              " 'inside_bus': 33,\n",
              " 'inside_subway': 34,\n",
              " 'jewelleryshop': 35,\n",
              " 'kindergarden': 36,\n",
              " 'kitchen': 37,\n",
              " 'laboratorywet': 38,\n",
              " 'laundromat': 39,\n",
              " 'library': 40,\n",
              " 'livingroom': 41,\n",
              " 'lobby': 42,\n",
              " 'locker_room': 43,\n",
              " 'mall': 44,\n",
              " 'meeting_room': 45,\n",
              " 'movietheater': 46,\n",
              " 'museum': 47,\n",
              " 'nursery': 48,\n",
              " 'office': 49,\n",
              " 'operating_room': 50,\n",
              " 'pantry': 51,\n",
              " 'poolinside': 52,\n",
              " 'prisoncell': 53,\n",
              " 'restaurant': 54,\n",
              " 'restaurant_kitchen': 55,\n",
              " 'shoeshop': 56,\n",
              " 'stairscase': 57,\n",
              " 'studiomusic': 58,\n",
              " 'subway': 59,\n",
              " 'toystore': 60,\n",
              " 'trainstation': 61,\n",
              " 'tv_studio': 62,\n",
              " 'videostore': 63,\n",
              " 'waitingroom': 64,\n",
              " 'warehouse': 65,\n",
              " 'winecellar': 66}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.25)\n",
        "print(len(train_idx), len(test_idx))\n",
        "\n",
        "# Create a DataLoader to load data in batches\n",
        "batch_size = 64\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    #shuffle=True,\n",
        "    sampler=train_sampler\n",
        "    )\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    #shuffle=True,\n",
        "    sampler=test_sampler\n",
        "    )\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for inputs, labels in train_dataloader:\n",
        "    print(inputs.shape, labels)\n",
        "    #print(labels.min(), labels.max())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVs4gDenV_LB",
        "outputId": "fddba6e6-3008-45f7-fda8-fa76498060e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11709 3904\n",
            "torch.Size([64, 3, 224, 224]) tensor([22, 40,  7,  3,  6, 38,  9, 46, 31, 30, 53, 54, 32, 19, 48,  7, 19, 19,\n",
            "         4, 36,  3, 50, 54, 57, 41, 12,  6, 47, 20,  0, 17, 43,  8, 43, 19,  4,\n",
            "        10, 54, 65, 21, 46, 48, 23, 60,  6,  3, 41, 64,  6,  1, 65, 28,  3, 41,\n",
            "        66, 10, 11, 22, 65,  3, 62, 52, 14,  6])\n"
          ]
        }
      ]
    }
  ]
}